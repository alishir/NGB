{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family:B Nazanin; font-size:20px\"> \n",
    "<center>\n",
    "<h1> بسم الله الرحمن الرحیم </h1>\n",
    "</center>\n",
    "<br/>\n",
    " این فایل تلاشی است برای استخراج گراف روات صحیح بخاری.\n",
    " \n",
    " در قسمت زیر نیازهای برنامه import شده‌اند\n",
    " به علاوه اینکه مقداری کد تست نیز در آن قرار داد.\n",
    " \n",
    " قسمت اصلی برنامه از بلاک بعدی آغاز می‌شود.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import io\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from pymongo import MongoClient\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.rawy_db\n",
    "collection = db.rawy_collection\n",
    "out_file = \"bokhari_graph.gpickle\"\n",
    "\n",
    "\n",
    "gx = nx.DiGraph()\n",
    "gx.add_node(u'1')\n",
    "for i in xrange(2):\n",
    "    hadithes=[]\n",
    "    hadithes.append(i)\n",
    "    gx.add_node(i, hadithes=hadithes)\n",
    "nx.set_node_attributes(gx, 'hadithes', {u'1': [23432, 234234]})\n",
    "gx.add_node(u'1', name='ali')\n",
    "attr = nx.get_node_attributes(gx, 'hadithes')\n",
    "gx.add_edge(u'1', u'2', count=12)\n",
    "print \"Get node attributes:\", attr\n",
    "print \"Get node data:\", gx.nodes()\n",
    "print gx.has_edge(u'2', u'1')\n",
    "print gx.has_edge(u'1', u'2')\n",
    "print nx.get_edge_attributes(gx, 'count')\n",
    "for edge in  gx.edges(data=True):\n",
    "    print edge\n",
    "    print \"{}-{}\".format(edge[0], edge[1])\n",
    "# nx.draw(gx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family:B Nazanin; font-size:20px\"> \n",
    "<h1>تشکیل گراف با استفاده از لیست احادیث islamwb </h1>\n",
    "<br/>\n",
    "در این قسمت مستندات مربوط به هر بخش را بنویسید.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "debug = False\n",
    "if debug:\n",
    "    start = 7020\n",
    "else:\n",
    "    start = 1\n",
    "\n",
    "for hadith in xrange(start, 7032):\n",
    "    if hadith % 1000 == 0:\n",
    "        print \"Processing hadith: {}\".format(hadith)\n",
    "    html = open('/home/ali/dl/datasets/mine/islamweb/bokhari/{}.html'.format(hadith), 'r').read();\n",
    "    soup = BeautifulSoup(html, 'html.parser');\n",
    "    tafseer = soup.find(id='tafseer0')\n",
    "    tag_names = [child.name for child in tafseer.p.findChildren(recursive=False)]\n",
    "    font_tag_index = tag_names.index('font')\n",
    "    last_br_index = len(tag_names) - tag_names[::-1].index('br')\n",
    "    tags = tafseer.p.findChildren(recursive=False)[last_br_index:font_tag_index]\n",
    "    \n",
    "    rawy_ids = [tag.get('href').split('=')[1] for tag in tags]\n",
    "    links = [(rawy_ids[i], rawy_ids[i+1]) for i in xrange(len(rawy_ids) - 1)]\n",
    "    g_hadith_attr = nx.get_node_attributes(g, 'hadithes')\n",
    "    g_edge_count_atter = nx.get_edge_attributes(g, 'count')\n",
    "    for tag in tags:\n",
    "        rawy_id = tag.get('href').split('=')[1]\n",
    "        rawy_name = tag.text\n",
    "        rawy_hadithes = []\n",
    "        if rawy_id in g_hadith_attr:\n",
    "            rawy_hadithes = g_hadith_attr[rawy_id]\n",
    "        rawy_hadithes.append(hadith)\n",
    "        g.add_node(rawy_id, hadithes=rawy_hadithes, name=rawy_name)\n",
    "    \n",
    "    for link in links:\n",
    "        if link in g_edge_count_atter:\n",
    "            count = g_edge_count_atter[link] + 1\n",
    "        else:\n",
    "            count = 1\n",
    "        g.add_edge(link[0], link[1], count=count)\n",
    "    \n",
    "# gpickle preservce single element lists while gml and gexf doesn't\n",
    "nx.write_gpickle(g, out_file)\n",
    "if debug:\n",
    "    print nx.get_edge_attributes(g, 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family:B Nazanin; font-size:20px\"> \n",
    "<h1> اضافه کردن تعداد احادیث</h1>\n",
    "<br/>\n",
    "در این قسمت تعداد احادیثی که هر راوی در سلسله سند آن وجود دارد به ویژگی‌های هر گره اضافه می‌شود.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 - Load raw graph from file\n",
    "g=nx.read_gpickle(out_file)\n",
    "attr = nx.get_node_attributes(g, 'hadithes')\n",
    "\n",
    "# 1- Add Hadith Count\n",
    "hadith_count = {}\n",
    "for n in attr:\n",
    "    hadith_count[n] = len(attr[n])\n",
    "nx.set_node_attributes(g, 'HadithCount', hadith_count)\n",
    "\n",
    "# 2- Add rawy class to graph\n",
    "rawy_class = {}\n",
    "for node in g.nodes():\n",
    "    rawy = collection.find_one({'id':node})\n",
    "    if rawy == None:\n",
    "        print \"E: rawy not found\", node\n",
    "    else:\n",
    "        try:\n",
    "            rc = int(rawy['class'])\n",
    "        except ValueError:\n",
    "            rc = -1\n",
    "            print 'E: rawy class is incorrent', node\n",
    "        rawy_class[node] = rc\n",
    "nx.set_node_attributes(g, 'RawyClass', rawy_class)\n",
    "\n",
    "# x- Save graph\n",
    "nx.write_gml(g, 'narrator_count.gml')\n",
    "nx.write_gpickle(g, out_file)\n",
    "\n",
    "# Some rawies doesn't find in data base, here is the list of them\n",
    "# Rawy not found: 5621\n",
    "# Rawy not found: 17772\n",
    "# Rawy not found: 22144\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family:B Nazanin; font-size:20px\"> \n",
    "<h1> اضافه کردن موقعیت هر راوی</h1>\n",
    "<br/>\n",
    " در این قسمت موقعیت مکانی هر راوی در گراف اضافه می‌شود.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=nx.read_gpickle(out_file)\n",
    "\n",
    "rawy_classes = nx.get_node_attributes(g, 'RawyClass')\n",
    "hadith_count = nx.get_node_attributes(g, 'HadithCount')\n",
    "edge_count = nx.get_edge_attributes(g, 'count')\n",
    "\n",
    "edge_ids = {}\n",
    "for edge in g.edges():\n",
    "    edge_ids[edge] = \"{}-{}\".format(edge[0], edge[1])\n",
    "nx.set_edge_attributes(g, \"id\", edge_ids)\n",
    "# print g.edges(data=True)\n",
    "\n",
    "min_class = min(rawy_classes.values())\n",
    "max_class = max(rawy_classes.values())\n",
    "print max_class\n",
    "print min_class\n",
    "\n",
    "rawies_in_class = {}\n",
    "node_x = {}\n",
    "node_y = {}\n",
    "vspace = 10\n",
    "hspace = 50\n",
    "y_base = 600\n",
    "for i in xrange(min_class, max_class + 1):\n",
    "    rawies_in_class[i] = [(k, hadith_count[k]) for k, v in rawy_classes.items() if v == i]\n",
    "    \n",
    "    # Bell sort rawies in each class base on hadith count\n",
    "    rawies_in_class[i].sort(key=lambda x: x[1])\n",
    "    subarray = [rawies_in_class[i][j::2] for j in xrange(2)]\n",
    "    subarray[1].reverse()\n",
    "    rawies_in_class[i] = sum(subarray, [])\n",
    "    \n",
    "    # first node position\n",
    "    first_y = y_base - ((len(rawies_in_class[i]) / 2) * vspace)\n",
    "    \n",
    "    # set node position\n",
    "    for node_count in enumerate(rawies_in_class[i]):\n",
    "        node = node_count[1][0]\n",
    "        node_x[node] = i * hspace\n",
    "        node_y[node] = first_y + node_count[0] * vspace\n",
    "    \n",
    "nx.set_node_attributes(g, 'x', node_x)\n",
    "nx.set_node_attributes(g, 'y', node_y)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Add colors\n",
    "# https://stackoverflow.com/questions/15140072/how-to-map-number-to-color-using-matplotlibs-colormap\n",
    "# -----------------------------------------------\n",
    "node_norm = mpl.colors.Normalize(vmin=min(hadith_count.values()), \n",
    "                            vmax=max(hadith_count.values()))\n",
    "edge_norm = mpl.colors.Normalize(vmin=min(edge_count.values()), \n",
    "                            vmax=max(edge_count.values()))\n",
    "node_map = cm.Greens\n",
    "edge_map = cm.Purples\n",
    "\n",
    "node_value2color = cm.ScalarMappable(norm=node_norm, cmap=node_map)\n",
    "edge_value2color = cm.ScalarMappable(norm=edge_norm, cmap=edge_map)\n",
    "\n",
    "# https://stackoverflow.com/questions/18337407/saving-utf-8-texts-in-json-dumps-as-utf8-not-as-u-escape-sequence\n",
    "# data = json_graph.node_link_data(g)  # I couldn't understand file format\n",
    "with io.open('graph.json', 'w', encoding='utf-8') as json_file:\n",
    "    header = \"\"\"\n",
    "    {\n",
    "        \"nodes\" : [\n",
    "    \"\"\"\n",
    "    json_file.write(unicode(header))\n",
    "    for node in g.nodes(data=True):\n",
    "        color = node_value2color.to_rgba(node[1]['HadithCount'], bytes=True)\n",
    "        try: \n",
    "            data = \"\"\"\n",
    "            {{\n",
    "                \"id\": \"{}\",\n",
    "                \"label\" : \"{}\",\n",
    "                \"size\" : {},\n",
    "                \"x\": {},\n",
    "                \"y\": {},\n",
    "                \"color\": \"rgba({}, {}, {}, {})\"\n",
    "            }},\\n\"\"\".format(node[0],\n",
    "                            node[1]['name'].encode('utf-8'), \n",
    "                            node[1]['HadithCount'], \n",
    "                            node[1]['x'],\n",
    "                            node[1]['y'],\n",
    "                            color[0], color[1], color[2], color[3]\n",
    "                          )\n",
    "            json_file.write(unicode(data))\n",
    "        except:\n",
    "            print node\n",
    "            print \"E: \"\n",
    "    json_file.write(unicode(\"\"\"\n",
    "        ],\n",
    "        \"edges\" :[\n",
    "    \"\"\"))\n",
    "    for edge in g.edges(data=True):\n",
    "        color = edge_value2color.to_rgba(edge[2]['count'], bytes=True)\n",
    "        data = \"\"\"\n",
    "        {{\n",
    "            \"id\" : \"{}\",\n",
    "            \"source\": \"{}\",\n",
    "            \"target\": \"{}\",\n",
    "            \"size\": {},\n",
    "            \"color\": \"rgba({}, {}, {}, {})\"\n",
    "        }},\n",
    "        \"\"\".format(\"{}-{}\".format(edge[0], edge[1]),\n",
    "                   edge[0],\n",
    "                   edge[1],\n",
    "                   edge[2]['count'],\n",
    "                   color[0], color[1], color[2], color[3])\n",
    "        json_file.write(unicode(data))\n",
    "    footer = \"\"\"\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    json_file.write(unicode(footer))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family:B Nazanin; font-size:20px\"> \n",
    "<h1>\n",
    "وارد کردن داده‌های هر راوی در دیتابیس\n",
    "</h1>\n",
    "<br/>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key2en = {\n",
    "u'الموالي' : u'Mawali',\n",
    "u'سنة الميلاد' : u'year_of_birth',\n",
    "u'النشاط' : u'activity',\n",
    "u'عمر الراوي' : u'age_of_transmitter',\n",
    "u'الطبقة' : u'class',\n",
    "u'الوصف' : u'description',\n",
    "u'النسب' : u'descent',\n",
    "u'الرتبة' : u'rank',\n",
    "u'الأقرباء' : u'relatives',\n",
    "u'اسم الشهرة' : u'nickname_ism',\n",
    "u'اسم الراوي' : u'transmitter_name',\n",
    "u'بلد الوفاة' : u'country_of_death',\n",
    "u'روى له' : u'narrated_him',\n",
    "u'الكنية' : u'nickname',\n",
    "u'اللقب' : u'title',\n",
    "u'النوع' : u'type',\n",
    "u'سنة الوفاة' : u'year_of_death',\n",
    "u'رقم الراوي' : u'id',\n",
    "u'المذهب' : u'doctrine',\n",
    "u'الإقامة' : u'residence'\n",
    "}\n",
    "\n",
    "def insert_rawy2db(rawy_id):\n",
    "    html = open('/home/ali/dl/datasets/mine/islamweb/rawy/{}.html'.format(rawy_id), 'r').read();\n",
    "    soup = BeautifulSoup(html, 'html.parser');\n",
    "    table = soup.find(id='table1')\n",
    "    rawy = {}\n",
    "    for row in table.find_all('tr'):\n",
    "        for col in enumerate(row.find_all('td')):\n",
    "            if col[0] % 2 == 0:\n",
    "                key = col[1].text\n",
    "            else:\n",
    "                try:\n",
    "                    value = col[1].find('input').get('value')\n",
    "                except:\n",
    "                    value = col[1].text\n",
    "                rawy[key2en[key.strip()]] = value.strip()\n",
    "    collection.insert_one(rawy)\n",
    "\n",
    "for rawy_id in xrange(1,9281):\n",
    "    insert_rawy2db(rawy_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add exceptional data\n",
    "for rawy_id in [1131, 5621, 17772, 22144]:\n",
    "    insert_rawy2db(rawy_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# استخراج نظر رجالی در مورد یک راوی\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs\n",
    "fn_path = \"/home/ali/dl/datasets/mine/islamweb/rawy/garh_5815.html\"\n",
    "\n",
    "with codecs.open(fn_path, encoding='windows-1256') as f:\n",
    "    content = f.read()\n",
    "    soup = BeautifulSoup(content.encode('utf-8'), \"html\")\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        row_id = cols[0].find('strong').text\n",
    "        crit_name = cols[1].find('strong').text\n",
    "        status = cols[2].find('strong').text\n",
    "        print crit_name, \"\\t\", status\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
